{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 3.6.3\"\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = read.csv(\"prlmis-data-full.csv\", header=TRUE, fileEncoding=\"UTF-8-BOM\")\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "# remove alternate response variables\n",
    "data = select(data, -c(\"PRLANY\",\"PRLMISAB\"))\n",
    "\n",
    "# update categorical values from raw dataset to be descriptive\n",
    "data$YEAR <- replace(data$YEAR, data$YEAR==\"15\", \"2015\")\n",
    "data$YEAR <- replace(data$YEAR, data$YEAR==\"16\", \"2016\")\n",
    "data$YEAR <- replace(data$YEAR, data$YEAR==\"17\", \"2017\")\n",
    "\n",
    "data$AGECAT <- replace(data$AGECAT, data$AGECAT==\"1\", \"12-17\")\n",
    "data$AGECAT <- replace(data$AGECAT, data$AGECAT==\"2\", \"18-25\")\n",
    "data$AGECAT <- replace(data$AGECAT, data$AGECAT==\"3\", \"26-35\")\n",
    "data$AGECAT <- replace(data$AGECAT, data$AGECAT==\"4\", \"36-49\")\n",
    "data$AGECAT <- replace(data$AGECAT, data$AGECAT==\"5\", \"50+\")\n",
    "\n",
    "data$SEX <- replace(data$SEX, data$SEX==\"0\", \"Male\")\n",
    "data$SEX <- replace(data$SEX, data$SEX==\"1\", \"Female\")\n",
    "\n",
    "data$MARRIED <- replace(data$MARRIED, data$MARRIED==\"0\", \"Unmarried\")\n",
    "data$MARRIED <- replace(data$MARRIED, data$MARRIED==\"1\", \"Divorced\")\n",
    "data$MARRIED <- replace(data$MARRIED, data$MARRIED==\"2\", \"Widowed\")\n",
    "data$MARRIED <- replace(data$MARRIED, data$MARRIED==\"3\", \"Married\")\n",
    "data$MARRIED <- replace(data$MARRIED, data$MARRIED==\"4\", \"Married\")\n",
    "\n",
    "data$EDUCAT <- replace(data$EDUCAT, data$EDUCAT==\"1\", \"School Age\")\n",
    "data$EDUCAT <- replace(data$EDUCAT, data$EDUCAT==\"2\", \"Some HS\")\n",
    "data$EDUCAT <- replace(data$EDUCAT, data$EDUCAT==\"3\", \"HS grad\")\n",
    "data$EDUCAT <- replace(data$EDUCAT, data$EDUCAT==\"4\", \"Some College\")\n",
    "data$EDUCAT <- replace(data$EDUCAT, data$EDUCAT==\"5\", \"College Grad\")\n",
    "\n",
    "data$EMPLOY18 <- replace(data$EMPLOY18, data$EMPLOY18==\"0\", \"Unemployed\")\n",
    "data$EMPLOY18 <- replace(data$EMPLOY18, data$EMPLOY18==\"1\", \"Part-Time\")\n",
    "data$EMPLOY18 <- replace(data$EMPLOY18, data$EMPLOY18==\"2\", \"Full-Time\")\n",
    "\n",
    "# wrong\n",
    "data$CTYMETRO <- replace(data$CTYMETRO, data$CTYMETRO==\"1\", \"Rural\")\n",
    "data$CTYMETRO <- replace(data$CTYMETRO, data$CTYMETRO==\"2\", \"Small\")\n",
    "data$CTYMETRO <- replace(data$CTYMETRO, data$CTYMETRO==\"3\", \"Large\")\n",
    "data$CTYMETRO <- replace(data$CTYMETRO, data$CTYMETRO==\"0\", \"na\")\n",
    "\n",
    "# convert categorical variables to factors\n",
    "data$YEAR<-as.factor(data$YEAR)\n",
    "data$AGECAT<-as.factor(data$AGECAT)\n",
    "data$SEX<-as.factor(data$SEX)\n",
    "data$MARRIED<-as.factor(data$MARRIED)\n",
    "data$EDUCAT<-as.factor(data$EDUCAT)\n",
    "data$EMPLOY18<-as.factor(data$EMPLOY18)\n",
    "data$CTYMETRO<-as.factor(data$CTYMETRO)\n",
    "#data$PRLMISEVR<-as.factor(data$PRLMISEVR)\n",
    "data$HEROINEVR<-as.factor(data$HEROINEVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>127738</li>\n",
       "\t<li>19</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 127738\n",
       "\\item 19\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 127738\n",
       "2. 19\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 127738     19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>42579</li>\n",
       "\t<li>19</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 42579\n",
       "\\item 19\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 42579\n",
       "2. 19\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 42579    19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train/test split\n",
    "set.seed(123)\n",
    "\n",
    "fractrain = 0.75\n",
    "fractest = 1-fractrain\n",
    "flag <- sort(sample(dim(data)[1], dim(data)[1]*fractest, replace = FALSE))\n",
    "train <- data[-flag,]\n",
    "test <- data[flag,]\n",
    "dim(train)\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gbm model\n",
    "library(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default gbm model\n",
    "gbm1 <- gbm(PRLMISEVR ~ ., data=train, distribution = 'bernoulli',\n",
    "            n.trees=2000,\n",
    "            cv.folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>var</th><th scope=col>rel.inf</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>HALUCNG</th><td>HALUCNG   </td><td>34.5456993</td></tr>\n",
       "\t<tr><th scope=row>COCAINE</th><td>COCAINE   </td><td>17.2879423</td></tr>\n",
       "\t<tr><th scope=row>AMPHETMN</th><td>AMPHETMN  </td><td>12.0156335</td></tr>\n",
       "\t<tr><th scope=row>TRQLZRS</th><td>TRQLZRS   </td><td>10.0844533</td></tr>\n",
       "\t<tr><th scope=row>MENTHLTH</th><td>MENTHLTH  </td><td> 7.2147968</td></tr>\n",
       "\t<tr><th scope=row>HEROINUSE</th><td>HEROINUSE </td><td> 4.1226177</td></tr>\n",
       "\t<tr><th scope=row>TRTMENT</th><td>TRTMENT   </td><td> 3.5967053</td></tr>\n",
       "\t<tr><th scope=row>HEROINEVR</th><td>HEROINEVR </td><td> 3.5230155</td></tr>\n",
       "\t<tr><th scope=row>SEDATVS</th><td>SEDATVS   </td><td> 2.2112590</td></tr>\n",
       "\t<tr><th scope=row>AGECAT</th><td>AGECAT    </td><td> 1.8794893</td></tr>\n",
       "\t<tr><th scope=row>MHTRTMT</th><td>MHTRTMT   </td><td> 1.3467648</td></tr>\n",
       "\t<tr><th scope=row>HEALTH</th><td>HEALTH    </td><td> 0.7848716</td></tr>\n",
       "\t<tr><th scope=row>MARRIED</th><td>MARRIED   </td><td> 0.3513962</td></tr>\n",
       "\t<tr><th scope=row>EMPLOY18</th><td>EMPLOY18  </td><td> 0.3213484</td></tr>\n",
       "\t<tr><th scope=row>CTYMETRO</th><td>CTYMETRO  </td><td> 0.2256812</td></tr>\n",
       "\t<tr><th scope=row>EDUCAT</th><td>EDUCAT    </td><td> 0.2130315</td></tr>\n",
       "\t<tr><th scope=row>SEX</th><td>SEX       </td><td> 0.1421354</td></tr>\n",
       "\t<tr><th scope=row>YEAR</th><td>YEAR      </td><td> 0.1331589</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & var & rel.inf\\\\\n",
       "\\hline\n",
       "\tHALUCNG & HALUCNG    & 34.5456993\\\\\n",
       "\tCOCAINE & COCAINE    & 17.2879423\\\\\n",
       "\tAMPHETMN & AMPHETMN   & 12.0156335\\\\\n",
       "\tTRQLZRS & TRQLZRS    & 10.0844533\\\\\n",
       "\tMENTHLTH & MENTHLTH   &  7.2147968\\\\\n",
       "\tHEROINUSE & HEROINUSE  &  4.1226177\\\\\n",
       "\tTRTMENT & TRTMENT    &  3.5967053\\\\\n",
       "\tHEROINEVR & HEROINEVR  &  3.5230155\\\\\n",
       "\tSEDATVS & SEDATVS    &  2.2112590\\\\\n",
       "\tAGECAT & AGECAT     &  1.8794893\\\\\n",
       "\tMHTRTMT & MHTRTMT    &  1.3467648\\\\\n",
       "\tHEALTH & HEALTH     &  0.7848716\\\\\n",
       "\tMARRIED & MARRIED    &  0.3513962\\\\\n",
       "\tEMPLOY18 & EMPLOY18   &  0.3213484\\\\\n",
       "\tCTYMETRO & CTYMETRO   &  0.2256812\\\\\n",
       "\tEDUCAT & EDUCAT     &  0.2130315\\\\\n",
       "\tSEX & SEX        &  0.1421354\\\\\n",
       "\tYEAR & YEAR       &  0.1331589\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | var | rel.inf |\n",
       "|---|---|---|\n",
       "| HALUCNG | HALUCNG    | 34.5456993 |\n",
       "| COCAINE | COCAINE    | 17.2879423 |\n",
       "| AMPHETMN | AMPHETMN   | 12.0156335 |\n",
       "| TRQLZRS | TRQLZRS    | 10.0844533 |\n",
       "| MENTHLTH | MENTHLTH   |  7.2147968 |\n",
       "| HEROINUSE | HEROINUSE  |  4.1226177 |\n",
       "| TRTMENT | TRTMENT    |  3.5967053 |\n",
       "| HEROINEVR | HEROINEVR  |  3.5230155 |\n",
       "| SEDATVS | SEDATVS    |  2.2112590 |\n",
       "| AGECAT | AGECAT     |  1.8794893 |\n",
       "| MHTRTMT | MHTRTMT    |  1.3467648 |\n",
       "| HEALTH | HEALTH     |  0.7848716 |\n",
       "| MARRIED | MARRIED    |  0.3513962 |\n",
       "| EMPLOY18 | EMPLOY18   |  0.3213484 |\n",
       "| CTYMETRO | CTYMETRO   |  0.2256812 |\n",
       "| EDUCAT | EDUCAT     |  0.2130315 |\n",
       "| SEX | SEX        |  0.1421354 |\n",
       "| YEAR | YEAR       |  0.1331589 |\n",
       "\n"
      ],
      "text/plain": [
       "          var       rel.inf   \n",
       "HALUCNG   HALUCNG   34.5456993\n",
       "COCAINE   COCAINE   17.2879423\n",
       "AMPHETMN  AMPHETMN  12.0156335\n",
       "TRQLZRS   TRQLZRS   10.0844533\n",
       "MENTHLTH  MENTHLTH   7.2147968\n",
       "HEROINUSE HEROINUSE  4.1226177\n",
       "TRTMENT   TRTMENT    3.5967053\n",
       "HEROINEVR HEROINEVR  3.5230155\n",
       "SEDATVS   SEDATVS    2.2112590\n",
       "AGECAT    AGECAT     1.8794893\n",
       "MHTRTMT   MHTRTMT    1.3467648\n",
       "HEALTH    HEALTH     0.7848716\n",
       "MARRIED   MARRIED    0.3513962\n",
       "EMPLOY18  EMPLOY18   0.3213484\n",
       "CTYMETRO  CTYMETRO   0.2256812\n",
       "EDUCAT    EDUCAT     0.2130315\n",
       "SEX       SEX        0.1421354\n",
       "YEAR      YEAR       0.1331589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAZlBMVEUAAAAAAP8AD/8AHv8A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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# divide plot area\n",
    "par(mfrow =c(1,1))\n",
    "summary(gbm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction     0     1\n",
       "         0 37435  3415\n",
       "         1   614  1115\n",
       "                                          \n",
       "               Accuracy : 0.9054          \n",
       "                 95% CI : (0.9026, 0.9081)\n",
       "    No Information Rate : 0.8936          \n",
       "    P-Value [Acc > NIR] : 6.296e-16       \n",
       "                                          \n",
       "                  Kappa : 0.3161          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : < 2.2e-16       \n",
       "                                          \n",
       "            Sensitivity : 0.9839          \n",
       "            Specificity : 0.2461          \n",
       "         Pos Pred Value : 0.9164          \n",
       "         Neg Pred Value : 0.6449          \n",
       "             Prevalence : 0.8936          \n",
       "         Detection Rate : 0.8792          \n",
       "   Detection Prevalence : 0.9594          \n",
       "      Balanced Accuracy : 0.6150          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get model predictions\n",
    "pred.gbm1 <- predict(gbm1, test, n.trees=2000, type=\"response\")\n",
    "pred.gbm1 <- replace(pred.gbm1, pred.gbm1>=0.5, 1)\n",
    "pred.gbm1 <- replace(pred.gbm1, pred.gbm1<0.5, 0)\n",
    "\n",
    "# output confusion matrix and error rate for gbm1\n",
    "pred.gbm1 <- as.factor(pred.gbm1)\n",
    "test$PRLMISEVR <- as.factor(test$PRLMISEVR)\n",
    "\n",
    "library(caret)\n",
    "confusionMatrix(pred.gbm1, test$PRLMISEVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1743"
      ],
      "text/latex": [
       "1743"
      ],
      "text/markdown": [
       "1743"
      ],
      "text/plain": [
       "[1] 1743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP8A/wBNTU1o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\nEgQQEgQQEgQQEgQQEgT4P7CNzBaRDcExAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "gbm.perf(gbm1, method = \"cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1743"
      ],
      "text/latex": [
       "1743"
      ],
      "text/markdown": [
       "1743"
      ],
      "text/plain": [
       "[1] 1743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build default gbm model\n",
    "gbm1 <- gbm(PRLMISEVR ~ ., data=train, distribution = 'bernoulli',\n",
    "            n.trees=2000,\n",
    "            cv.folds = 3)\n",
    "\n",
    "# find best number of trees\n",
    "best.ntrees <- which.min(gbm1$cv.error)\n",
    "best.ntrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default gbm model\n",
    "gbm1 <- gbm(PRLMISEVR ~ ., data=train, distribution = 'bernoulli',\n",
    "            n.trees=2000,\n",
    "            cv.folds = 3)\n",
    "\n",
    "# create parameter grid to find best shrinkage and interaction depth\n",
    "hyper_grid <- expand.grid(\n",
    "  shrinkage = c(.05, .1, .2),\n",
    "  interaction.depth = c(1, 3, 5),\n",
    "  optimal_trees = 0,               \n",
    "  min_loss = 0                     \n",
    ")\n",
    "\n",
    "# grid search \n",
    "for(i in 1:nrow(hyper_grid)) {\n",
    "    set.seed(123)\n",
    "    \n",
    "    # train model\n",
    "    gbm.tune <- gbm(PRLMISEVR ~ ., data=train,\n",
    "                    distribution = \"bernoulli\",\n",
    "                    n.trees = 2000,\n",
    "                    shrinkage = hyper_grid$shrinkage[i],\n",
    "                    interaction.depth = hyper_grid$interaction.depth[i],\n",
    "                    train.fraction = .75,\n",
    "                    cv.folds=2,\n",
    "                    n.cores = NULL, # will use all cores by default\n",
    "                    verbose = FALSE\n",
    "                   )\n",
    "    \n",
    "    # add min training error and trees to grid\n",
    "    hyper_grid$optimal_trees[i] <- which.min(gbm.tune$cv.error)\n",
    "    hyper_grid$min_loss[i] <- min(gbm.tune$cv.error)\n",
    "}\n",
    "\n",
    "# arrange in order of best performance\n",
    "hyper_grid <- hyper_grid %>% arrange(min_loss) %>% head(10)\n",
    "\n",
    "# build optimized gbm model\n",
    "gbm2 <- gbm(PRLMISEVR ~ ., data=train, distribution = 'bernoulli',\n",
    "            n.trees=hyper_grid$optimal_trees[1],\n",
    "            shrinkage=hyper_grid$shrinkage[1],\n",
    "            interaction.depth=hyper_grid$interaction.depth[1],\n",
    "            cv.folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search \n",
    "for(i in 1:nrow(hyper_grid)) {\n",
    "    set.seed(123)\n",
    "    \n",
    "    # train model\n",
    "    gbm.tune <- gbm(PRLMISEVR ~ ., data=train,\n",
    "                    distribution = \"bernoulli\",\n",
    "                    n.trees = 2000,\n",
    "                    shrinkage = hyper_grid$shrinkage[i],\n",
    "                    interaction.depth = hyper_grid$interaction.depth[i],\n",
    "                    train.fraction = .75,\n",
    "                    cv.folds=2,\n",
    "                    n.cores = NULL, # will use all cores by default\n",
    "                    verbose = FALSE\n",
    "                   )\n",
    "    \n",
    "    # add min training error and trees to grid\n",
    "    hyper_grid$optimal_trees[i] <- which.min(gbm.tune$cv.error)\n",
    "    hyper_grid$min_loss[i] <- min(gbm.tune$cv.error)\n",
    "}\n",
    "\n",
    "hyper_grid <- hyper_grid %>% arrange(min_loss) %>% head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>shrinkage</th><th scope=col>interaction.depth</th><th scope=col>optimal_trees</th><th scope=col>min_loss</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.05     </td><td>5        </td><td>543      </td><td>0.5898498</td></tr>\n",
       "\t<tr><td>0.05     </td><td>3        </td><td>853      </td><td>0.5899293</td></tr>\n",
       "\t<tr><td>0.10     </td><td>3        </td><td>456      </td><td>0.5902036</td></tr>\n",
       "\t<tr><td>0.10     </td><td>5        </td><td>249      </td><td>0.5905598</td></tr>\n",
       "\t<tr><td>0.20     </td><td>3        </td><td>248      </td><td>0.5913094</td></tr>\n",
       "\t<tr><td>0.20     </td><td>5        </td><td> 92      </td><td>0.5919366</td></tr>\n",
       "\t<tr><td>0.05     </td><td>1        </td><td>870      </td><td>0.6046635</td></tr>\n",
       "\t<tr><td>0.10     </td><td>1        </td><td>546      </td><td>0.6046678</td></tr>\n",
       "\t<tr><td>0.20     </td><td>1        </td><td>320      </td><td>0.6046870</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " shrinkage & interaction.depth & optimal\\_trees & min\\_loss\\\\\n",
       "\\hline\n",
       "\t 0.05      & 5         & 543       & 0.5898498\\\\\n",
       "\t 0.05      & 3         & 853       & 0.5899293\\\\\n",
       "\t 0.10      & 3         & 456       & 0.5902036\\\\\n",
       "\t 0.10      & 5         & 249       & 0.5905598\\\\\n",
       "\t 0.20      & 3         & 248       & 0.5913094\\\\\n",
       "\t 0.20      & 5         &  92       & 0.5919366\\\\\n",
       "\t 0.05      & 1         & 870       & 0.6046635\\\\\n",
       "\t 0.10      & 1         & 546       & 0.6046678\\\\\n",
       "\t 0.20      & 1         & 320       & 0.6046870\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| shrinkage | interaction.depth | optimal_trees | min_loss |\n",
       "|---|---|---|---|\n",
       "| 0.05      | 5         | 543       | 0.5898498 |\n",
       "| 0.05      | 3         | 853       | 0.5899293 |\n",
       "| 0.10      | 3         | 456       | 0.5902036 |\n",
       "| 0.10      | 5         | 249       | 0.5905598 |\n",
       "| 0.20      | 3         | 248       | 0.5913094 |\n",
       "| 0.20      | 5         |  92       | 0.5919366 |\n",
       "| 0.05      | 1         | 870       | 0.6046635 |\n",
       "| 0.10      | 1         | 546       | 0.6046678 |\n",
       "| 0.20      | 1         | 320       | 0.6046870 |\n",
       "\n"
      ],
      "text/plain": [
       "  shrinkage interaction.depth optimal_trees min_loss \n",
       "1 0.05      5                 543           0.5898498\n",
       "2 0.05      3                 853           0.5899293\n",
       "3 0.10      3                 456           0.5902036\n",
       "4 0.10      5                 249           0.5905598\n",
       "5 0.20      3                 248           0.5913094\n",
       "6 0.20      5                  92           0.5919366\n",
       "7 0.05      1                 870           0.6046635\n",
       "8 0.10      1                 546           0.6046678\n",
       "9 0.20      1                 320           0.6046870"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyper_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optimized gbm model\n",
    "gbm2 <- gbm(PRLMISEVR ~ ., data=train, distribution = 'bernoulli',\n",
    "            n.trees=hyper_grid$optimal_trees[1],\n",
    "            shrinkage=hyper_grid$shrinkage[1],\n",
    "            interaction.depth=hyper_grid$interaction.depth[1],\n",
    "            cv.folds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction     0     1\n",
       "         0 37436  3338\n",
       "         1   613  1192\n",
       "                                          \n",
       "               Accuracy : 0.9072          \n",
       "                 95% CI : (0.9044, 0.9099)\n",
       "    No Information Rate : 0.8936          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.3361          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : < 2.2e-16       \n",
       "                                          \n",
       "            Sensitivity : 0.9839          \n",
       "            Specificity : 0.2631          \n",
       "         Pos Pred Value : 0.9181          \n",
       "         Neg Pred Value : 0.6604          \n",
       "             Prevalence : 0.8936          \n",
       "         Detection Rate : 0.8792          \n",
       "   Detection Prevalence : 0.9576          \n",
       "      Balanced Accuracy : 0.6235          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get model predictions\n",
    "pred.gbm2 <- predict(gbm2, test, n.trees=hyper_grid$optimal_trees[1], type=\"response\")\n",
    "pred.gbm2 <- replace(pred.gbm2, pred.gbm2>=0.5, 1)\n",
    "pred.gbm2 <- replace(pred.gbm2, pred.gbm2<0.5, 0)\n",
    "\n",
    "# output confusion matrix and error rate for gbm2\n",
    "pred.gbm2 <- as.factor(pred.gbm2)\n",
    "confusionMatrix(pred.gbm2, test$PRLMISEVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM Error before tuning:  0.09462411 \n",
      "GBM Error after tuning:  0.09279222"
     ]
    }
   ],
   "source": [
    "# get error\n",
    "gbm1.error = mean(pred.gbm1 != test$PRLMISEVR)\n",
    "gbm2.error = mean(pred.gbm2 != test$PRLMISEVR)\n",
    "cat(\"GBM Error before tuning: \", gbm1.error, \"\\n\")\n",
    "cat(\"GBM Error after tuning: \", gbm2.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
